{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß¨ Clustering de cellules canc√©reuses\n",
    "Nous allons utiliser des m√©thodes de r√©duction de dimension (PCA) et de clustering (k-means) afin de regrouper des cellules canc√©reuses (issues de sous-types de cancer distincts) en fonction de leur expression g√©nique. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üíæ Donn√©es\n",
    "\n",
    "> L'ensemble de donn√©e (dataset) que nous allons utiliser contient les valeurs d'expression g√©nique de cellules canc√©reuses. Ces donn√©es sont extraites d'un manuscrit r√©dig√© par les chercheurs du projet d'analyse pan-canc√©reuse The Cancer Genome Atlas (TCGA).\n",
    " \n",
    "> Il y a 881 √©chantillons (lignes) repr√©sentant 5 sous-types de cancer distincts. Chaque √©chantillon comporte les valeurs d'expression g√©nique pour 20 531 g√®nes (colonnes). L'ensemble de donn√©es est disponible sur le UC Irvine Machine Learning Repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üì§ Import des Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import urllib\n",
    "\n",
    "import pandas as pd # Analyse et manipulation de donn√©es (utilisation des Panda DataFrame) https://pandas.pydata.org/docs/user_guide/index.html and/or https://sparkbyexamples.com/python-pandas-tutorial-for-beginners/ \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # Visualization de donn√©es\n",
    "#import hvplot.pandas # Plots interactifs https://hvplot.holoviz.org/\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T√©l√©chargement et extraction du dataset\n",
    "\n",
    "Vous pouvez √©galement t√©l√©chager manuellement les fichiers de donn√©es depuis: https://archive.ics.uci.edu/dataset/401/gene+expression+cancer+rna+seq \n",
    "\n",
    "L'archive t√©l√©charg√©e devra alors √™tre d√©-zipp√©e et enregistr√©e dans le dossier courrant: **Unige_ml/Day_1_TP_2_Clustering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "uci_tcga_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00401/\"\n",
    "archive_name = \"TCGA-PANCAN-HiSeq-801x20531.tar.gz\"\n",
    "\n",
    "# URL\n",
    "full_download_url = urllib.parse.urljoin(uci_tcga_url, archive_name)\n",
    "\n",
    "# T√©l√©charger le fichier\n",
    "r = urllib.request.urlretrieve (full_download_url, archive_name)\n",
    "\n",
    "# Extraire les donn√©es de l'archive\n",
    "tar = tarfile.open(archive_name, \"r:gz\")\n",
    "tar.extractall()\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = \"TCGA-PANCAN-HiSeq-801x20531/data.csv\"\n",
    "labels_file = \"TCGA-PANCAN-HiSeq-801x20531/labels.csv\"\n",
    "\n",
    "# Charger les donn√©es du fichier 'datafile'\n",
    "data = np.genfromtxt(\n",
    "    datafile,\n",
    "    delimiter=\",\",\n",
    "    usecols=range(1, 20532),\n",
    "    skip_header=1\n",
    ")\n",
    "\n",
    "# Charger les √©tiquettes du fichier 'labels_file'\n",
    "true_label_names = np.genfromtxt(\n",
    "    labels_file,\n",
    "    delimiter=\",\",\n",
    "    usecols=(1,),\n",
    "    skip_header=1,\n",
    "    dtype=\"str\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V√©rifions la taille des donn√©es; i.e.,\n",
    "- Nombre d'√©chantillons (Nombre de lignes)\n",
    "- Nombre de g√®nes (Nombre de colonnes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(801, 20531)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruction**: V√©rifiez que le nombre d'√©tiquettes est consitent avec le nombre d'√©chantillons\n",
    "\n",
    "<details>\n",
    "<summary>Aide</summary>\n",
    "\n",
    "1) <a href=\"https://numpy.org/doc/stable/reference/generated/numpy.shape.html\">Utilisez numpy.shape</a>\n",
    "\n",
    "2) Les √©tiquettes sont dans `true_label_names`\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consultons les premi√®res lignes et colonnes des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 2.01720929, 3.26552691],\n",
       "       [0.        , 0.59273209, 1.58842082],\n",
       "       [0.        , 3.51175898, 4.32719872],\n",
       "       [0.        , 3.66361787, 4.50764878],\n",
       "       [0.        , 2.65574107, 2.82154696]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5,:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**instruction** Consultez les √©tiquettes des 5 premiers √©chantillons\n",
    "\n",
    "<details>\n",
    "<summary>Aide</summary>\n",
    "Ce sont les 5 premiers √©l√©ments de `true_label_names`\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code ici\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BRCA', 'COAD', 'KIRC', 'LUAD', 'PRAD'], dtype='<U4')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Valeurs uniques dans le tableau des √©tiquettes de r√©f√©rence\n",
    "np.unique(true_label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convertir les abr√©viations en entiers avec LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3, 4, 4, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode les √©tiquettes avec des valeurs entre 0 et le nombre de classes\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "true_labels = label_encoder.fit_transform(true_label_names)\n",
    "true_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BRCA', 'COAD', 'KIRC', 'LUAD', 'PRAD'], dtype='<U4')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# √âtant donn√© que l'encodeur a √©t√© ajust√© aux donn√©es, vous pouvez voir les classes uniques repr√©sent√©es en utilisant .classes_.label_encoder.classes_\n",
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruction**: Fixer le nombre de clusters aux nombres de classes uniques repr√©sent√©es\n",
    "<details>\n",
    "<summary>Aide</summary>\n",
    "Vous pouvez utiliser la fonction \n",
    "<a href=\"https://www.w3schools.com/python/ref_func_len.asp\">`len(...)`</a>\n",
    " \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code ici\n",
    "n_clusters = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Pipeline\n",
    "## Pipeline pour traiter les donn√©es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruction**: Fixez le nombre de composantes principales √† 2 pour la m√©thode PCA\n",
    "<details>\n",
    "<summary>Aide</summary>\n",
    "Indiquez l'argument `n_components`\n",
    "\n",
    "Voir <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\">Documentation PCA</a>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation et r√©duction de dimension\n",
    "preprocessor = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", MinMaxScaler()),\n",
    "        # Code ici\n",
    "        (\"pca\", PCA(None,random_state=42))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline pour effectuer le clustering K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer = Pipeline(\n",
    "   [\n",
    "       (\n",
    "           \"kmeans\",\n",
    "           KMeans(\n",
    "               n_clusters=n_clusters,\n",
    "               init=\"k-means++\",\n",
    "               n_init=50,\n",
    "               max_iter=500,\n",
    "               random_state=42,\n",
    "           ),\n",
    "       ),\n",
    "   ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encha√Æner les pipelines de pr√©traitement et de clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"clusterer\", clusterer)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appliquer les √©tapes du pipeline sur les donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'n_clusters' parameter of KMeans must be an int in the range [1, inf). Got None instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/pipeline.py:420\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    419\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 420\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_last_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/pipeline.py:420\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    419\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 420\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_last_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/base.py:1144\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m partial_fit_and_fitted \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1140\u001b[0m     fit_method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpartial_fit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m _is_fitted(estimator)\n\u001b[1;32m   1141\u001b[0m )\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m global_skip_validation \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m partial_fit_and_fitted:\n\u001b[0;32m-> 1144\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/base.py:637\u001b[0m, in \u001b[0;36mBaseEstimator._validate_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_params\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    630\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[1;32m    631\u001b[0m \n\u001b[1;32m    632\u001b[0m \u001b[38;5;124;03m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;124;03m    accepted constraints.\u001b[39;00m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 637\u001b[0m     \u001b[43mvalidate_parameter_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parameter_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcaller_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:95\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[0;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     90\u001b[0m     constraints_str \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m     )\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m )\n",
      "\u001b[0;31mInvalidParameterError\u001b[0m: The 'n_clusters' parameter of KMeans must be an int in the range [1, inf). Got None instead."
     ]
    }
   ],
   "source": [
    "pipe.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rifie le r√©sultat de la r√©duction de dimension (Transformation en 2D)\n",
    "preprocessed_data = pipe[\"preprocessor\"].transform(data)\n",
    "preprocessed_data[:5,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rifie le r√©sultat du clustering\n",
    "predicted_labels = pipe[\"clusterer\"][\"kmeans\"].labels_\n",
    "print(predicted_labels.shape)\n",
    "print(predicted_labels[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# √âvaluer la qualit√© du clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruction**: Calculez le coefficient de silhouette en fonction des donn√©es r√©duites `preprocessed_data` et des clusters attribu√©s `predicted_labels` \n",
    "<details>\n",
    "<summary>Aide</summary>\n",
    "Utilisez la fonction \n",
    "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html\">`silhouette_score(...)`</a>\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Profitons d'avoir les √©tiquettes de r√©f√©rence pour calculer une deuxi√®me mesure de qualit√© du clustering :) \n",
    "\n",
    "**Instruction**: Calculez l'Indice de Rand Ajust√© (ARI) en fonction des √©tiquettes de r√©f√©rence `true_labels` et des clusters attribu√©s `predicted_labels` \n",
    "<details>\n",
    "<summary>Aide</summary>\n",
    "Utilisez la fonction \n",
    "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_rand_score.html\">`adjusted_rand_score(...)`</a>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualiser les donn√©es dans le contexte des √©tiquettes r√©elles et des √©tiquettes pr√©dites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construit le dataframe avec la projection des donn√©es en 2D, leurs clusters pr√©dits, et leurs √©tiquettes de r√©f√©rence\n",
    "pcadf = pd.DataFrame(\n",
    "    pipe[\"preprocessor\"].transform(data)[:,:2],\n",
    "    columns=[\"component_1\", \"component_2\"],\n",
    ")\n",
    "\n",
    "pcadf[\"predicted_cluster\"] = pipe[\"clusterer\"][\"kmeans\"].labels_\n",
    "pcadf[\"true_label\"] = label_encoder.inverse_transform(true_labels)\n",
    "pcadf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "scat = sns.scatterplot(\n",
    "    data=pcadf,\n",
    "    x = \"component_1\",\n",
    "    y = \"component_2\",\n",
    "    s=50,\n",
    "    hue=\"predicted_cluster\",\n",
    "    style=\"true_label\",\n",
    "    palette=\"Set2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION:** \n",
    "- Comparez les clusters/√©tiquettes pr√©dites (couleurs) et les √©tiquettes r√©elles (formes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R√©glage des param√®tres\n",
    "Et si nous ne connaissions pas les √©tiquettes r√©elles des donn√©es...\n",
    "\n",
    "1) __Comment aurions-nous pu \"trouver\" le nombre de clusters (2, 5 ou 20 types de cellules)?__\n",
    "\n",
    "2) __Pourquoi baser le clustering sur 2 dimensions seulement? Pourrions-nous obtenir de meilleurs r√©sultats avec davantage de dimensions/composantes?__\n",
    "\n",
    "## R√©duction de dimension\n",
    "Utilisez les la variance expliqu√©e cumul√©e pour identifier le nombre appropri√© de composantes principales √† garder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R√©cup√©re et visualise la variance expliqu√©e cumul√©e par les 20 premi√®res composantes\n",
    "m = 20\n",
    "pipe[\"preprocessor\"][\"pca\"].n_components = m\n",
    "pipe.fit(data)\n",
    "pipe[\"preprocessor\"][\"pca\"].explained_variance_\n",
    "plt.plot(\n",
    "    range(1, m+1),\n",
    "    np.cumsum(pipe[\"preprocessor\"][\"pca\"].explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION:**\n",
    "\n",
    "A partir d''un certain nombre de composantes principales, le gain en terme de variance expliqu√©e devient moindre.\n",
    "\n",
    "- A combien estimez-vous ce nombre (de composantes principales)?\n",
    "\n",
    "N'h√©sitez pas √† tester dans la suite du code diff√©rentes valeurs pour le nombre de composantes principales √† garder/utiliser et √©valuer l'impact sur le clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "Enfin, utilisons les m√©triques de qualit√© de clustering pour d√©finir le nombre clusters\n",
    "\n",
    "**Instruction**: \n",
    "- Fixez le nombre de composantes principales `n_components` √† 7\n",
    "- Faites varier le nombre de clusters `n_clusters` de 2 √† 10\n",
    "<details>\n",
    "<summary>Aide</summary>\n",
    "\n",
    "- Vous pouvez acc√©der aux hyperparam√®tre de la PCA, √† travers `pipe[\"preprocessor\"][\"pca\"]`\n",
    "\n",
    "- Vous pouvez acc√©der aux hyperparam√®tre de K-means clustering, √† travers `pipe[\"clusterer\"][\"kmeans\"]`\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listes vides pour stocker les m√©triques de qualit√© \n",
    "# Silhouette\n",
    "silhouette_scores = []\n",
    "# Index Rand Ajust√©\n",
    "ari_scores = []\n",
    "for n in range(2, 11):\n",
    "    # Faites varier le nombre de clusters,\n",
    "    # et laissez le nombre de composantes principales fix√© √† 7\n",
    "    ### Code ici - D√©but ###\n",
    "    \n",
    "    \n",
    "    ### Code ici - Fin ###\n",
    "    pipe.fit(data)\n",
    "\n",
    "    silhouette_coef = silhouette_score(\n",
    "        pipe[\"preprocessor\"].transform(data),\n",
    "        pipe[\"clusterer\"][\"kmeans\"].labels_,\n",
    "    )\n",
    "    ari = adjusted_rand_score(\n",
    "        true_labels,\n",
    "        pipe[\"clusterer\"][\"kmeans\"].labels_,\n",
    "    )\n",
    "\n",
    "    # Ajoute les m√©triques aux listes correspondantes\n",
    "    silhouette_scores.append(silhouette_coef)\n",
    "    ari_scores.append(ari)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisez la relation entre le nombre de clusters et la qualit√© du clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"fivethirtyeight\")\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(\n",
    "    range(2, 11),\n",
    "    silhouette_scores,\n",
    "    c=\"#008fd5\",\n",
    "    label=\"Silhouette Coefficient\",\n",
    ")\n",
    "plt.plot(range(2, 11), ari_scores, c=\"#fc4f30\", label=\"ARI\")\n",
    "\n",
    "plt.xlabel(\"n_clusters\")\n",
    "plt.legend()\n",
    "plt.title(\"Clustering Performance as a Function of n_clusters\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# üìù R√©sum√©\n",
    "Dans ce notebook, vous avez utilis√© des m√©thodes de dimension de r√©duction et de clustering pour le regroupement automatique de cellules canc√©reuses.\n",
    "\n",
    "Vous avez couvert les aspects suivants:\n",
    "> - Le mod√®le de r√©duction de dimension PCA\n",
    "> - Le mod√®le de clustering K-means\n",
    "> - L'exploration et la pr√©paration des donn√©es avant leur utilisation pour la r√©duction de dimension et le clustering\n",
    "> - L'entrainement des deux mod√®les PCA et K-means\n",
    "> - L'exploration des hyperparam√®tres des deux mod√®les, i.e., nombre de composantes principales, et nombre de clusters\n",
    "> - L'√©valuation de la qualit√© du clustering √† l'aide du coefficient Silhouette et Score de Rand Ajust√© \n",
    "\n",
    "\n",
    "# üîó References:\n",
    "- [Scikit-learn library - Clustering](https://scikit-learn.org/stable/modules/clustering.html)\n",
    "- [K-Means Clustering in Python: A Practical Guide](https://realpython.com/k-means-clustering-python/)\n",
    "- [How to Select the Best Number of Principal Components for the Dataset](https://towardsdatascience.com/how-to-select-the-best-number-of-principal-components-for-the-dataset-287e64b14c6d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
