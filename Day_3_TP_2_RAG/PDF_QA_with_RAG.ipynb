{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "018d76a9",
   "metadata": {},
   "source": [
    "\n",
    "# Building a PDF Question Answering (QA) System using RAG\n",
    "> In this notebook, you will create a system that answers questions based on the content of a PDF file. \n",
    "> This involves building a Retrieval-Augmented Generation (RAG) pipeline, where relevant document sections \n",
    "> are retrieved based on the question and used to generate precise answers.\n",
    "\n",
    "## Key Components:\n",
    "1. **Document Loading** - Load and preprocess PDF content for analysis.\n",
    "2. **Indexing** - Split and store text in a vectorized format for fast retrieval.\n",
    "3. **Retrieval** - Retrieve relevant document sections for a given query.\n",
    "4. **Generation** - Use a language model to generate an answer based on the retrieved context.\n",
    "\n",
    "Let's dive in!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea7bd9e",
   "metadata": {},
   "source": [
    "\n",
    "# ðŸ“¥ Library Installation\n",
    "We install the necessary libraries to process PDFs, handle embeddings, and work with language models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.11 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: faiss-cpu in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.9.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in /Users/azizamerzouki/Library/Python/3.11/lib/python/site-packages (from faiss-cpu) (24.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.11 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain-openai in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.2.8)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain-openai) (0.3.18)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.54.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain-openai) (1.54.4)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain-openai) (0.8.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.17->langchain-openai) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.17->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.17->langchain-openai) (0.1.143)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/azizamerzouki/Library/Python/3.11/lib/python/site-packages (from langchain-core<0.4.0,>=0.3.17->langchain-openai) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.17->langchain-openai) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.17->langchain-openai) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/azizamerzouki/Library/Python/3.11/lib/python/site-packages (from langchain-core<0.4.0,>=0.3.17->langchain-openai) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (0.7.1)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (4.67.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.54.0->langchain-openai) (3.10)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain-openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain-openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.17->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.17->langchain-openai) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.17->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.17->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.17->langchain-openai) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.2.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.11 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU pypdf langchain_community\n",
    "%pip install faiss-cpu\n",
    "%pip install langchain-openai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“¤ Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import config  # Importing the config file\n",
    "import faiss\n",
    "import numpy as np\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_openai import OpenAIEmbeddings, OpenAI\n",
    "from langchain_community.vectorstores import FAISS # A library for efficient similarity search and clustering of dense vectors.\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prepration\n",
    "## Loading Documents\n",
    "> First, you'll need to choose a PDF to load. Feel free to use a PDF of your choosing.\n",
    "> Once you've chosen your PDF, the next step is to load it into a format that an LLM can more easily handle, since LLMs generally require text inputs. \n",
    "> LangChain has a few different built-in PDF document loaders for this purpose which you can experiment with. \n",
    "\n",
    "> Below, we'll use one powered by the <a href=\"https://pypi.org/project/pypdf/\">pypdf</a> package that reads from a filepath.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Documents\n",
    "\n",
    "# Example document\n",
    "file_path = \"./example_data/journal.pone.0264429.pdf\"\n",
    "\n",
    "# The loader reads the PDF at the specified path into memory.\n",
    "loader = PyPDFLoader(file_path)\n",
    "\n",
    "# Extract text data using the pypdf package.\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore loaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# Type and length of docs\n",
    "print(type(docs))\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What do each element of the variable docs represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of docs elements: \n",
      "<class 'langchain_core.documents.base.Document'>\n",
      "\n",
      "First element of loaded data docs: \n",
      "page_content='RESEA RCH ARTICL E\n",
      "Prediction of HIV status based on socio-\n",
      "behavioural characteristics in East and\n",
      "Southern Africa\n",
      "Erol Orel\n",
      "ID\n",
      "1\n",
      "*, Rachel Esra\n",
      "1\n",
      ", Janne Estill\n",
      "1,2\n",
      ", Amaury Thiabaud\n",
      "ID\n",
      "1\n",
      ", Ste Â´ phane Marchand-\n",
      "Maillet\n",
      "ID\n",
      "3\n",
      ", Aziza Merzouki\n",
      "1â˜¯\n",
      ", Olivia Keiser\n",
      "1â˜¯\n",
      "1 Institute of Global Health, University of Geneva, Geneva , Switzerlan d, 2 Institute of Mathematic al Statistics\n",
      "and Actuari al Science, Univers ity of Bern, Bern, Switzerlan d, 3 Department of Computer Science, Viper\n",
      "Group, University of Geneva, Geneva , Switzerlan d\n",
      "â˜¯ These authors contribu ted equally to this work.\n",
      "* Erol.Ore l@unige.ch\n",
      "Abstract\n",
      "Introduction\n",
      "High yield HIV testing strategies are critical to reach epidemic control in high prevalence and\n",
      "low-resource settings such as East and Southern Africa. In this study, we aimed to predict\n",
      "the HIV status of individuals living in Angola, Burundi, Ethiopia, Lesotho, Malawi, Mozam-\n",
      "bique, Namibia, Rwanda, Zambia and Zimbabwe with the highest precision and sensitivity\n",
      "for different policy targets and constraints based on a minimal set of socio-behavioural\n",
      "characteristics.\n",
      "Methods\n",
      "We analysed the most recent Demographic and Health Survey from these 10 countries to\n",
      "predict individualâ€™s HIV status using four different algorithms (a penalized logistic regression,\n",
      "a generalized additive model, a support vector machine, and a gradient boosting trees). The\n",
      "algorithms were trained and validated on 80% of the data, and tested on the remaining 20%.\n",
      "We compared the predictions based on the F1 score, the harmonic mean of sensitivity and\n",
      "positive predictive value (PPV), and we assessed the generalization of our models by test-\n",
      "ing them against an independent left-out country. The best performing algorithm was trained\n",
      "on a minimal subset of variables which were identified as the most predictive, and used to 1)\n",
      "identify 95% of people living with HIV (PLHIV) while maximising precision and 2) identify\n",
      "groups of individuals by adjusting the probability threshold of being HIV positive (90% in our\n",
      "scenario) for achieving specific testing strategies.\n",
      "Results\n",
      "Overall 55,151 males and 69,626 females were included in the analysis. The gradient boost-\n",
      "ing trees algorithm performed best in predicting HIV status with a mean F1 score of 76.8%\n",
      "[95% confidence interval (CI) 76.0%-77.6%] for males (vs [CI 67.8%-70.6%] for SVM) and\n",
      "78.8% [CI 78.2%-79.4%] for females (vs [CI 73.4%-75.8%] for SVM). Among the ten most\n",
      "PLOS ONE\n",
      "PLOS ONE | https://doi.or g/10.137 1/journal.po ne.02644 29 March 3, 2022 1 / 15\n",
      "a1111111111\n",
      "a1111111111\n",
      "a1111111111\n",
      "a1111111111\n",
      "a1111111111\n",
      "OPEN ACCESS\n",
      "Citation: Orel E, Esra R, Estill J, Thiabaud A,\n",
      "Marchand-M aillet S, Merzouki A, et al. (2022)\n",
      "Prediction of HIV status based on socio-\n",
      "behavioural characteristi cs in East and Southern\n",
      "Africa. PLoS ONE 17(3): e0264429. https:// doi.org/\n",
      "10.1371/ journal.pone. 0264429\n",
      "Editor: Daniel Boateng, Julius Centre, University\n",
      "Medical Centre, Utrecht, NETHERLA NDS\n",
      "Received: March 29, 2021\n",
      "Accepted: February 10, 2022\n",
      "Published: March 3, 2022\n",
      "Peer Review History: PLOS recognize s the\n",
      "benefits of transpar ency in the peer review\n",
      "process; therefore, we enable the publication of\n",
      "all of the content of peer review and author\n",
      "response s alongside final, published articles. The\n",
      "editorial history of this article is available here:\n",
      "https://doi.o rg/10.1371/jo urnal.pone.0 264429\n",
      "Copyright: Â© 2022 Orel et al. This is an open\n",
      "access article distributed under the terms of the\n",
      "Creative Commons Attribution License, which\n",
      "permits unrestricte d use, distribu tion, and\n",
      "reproduction in any medium, provided the original\n",
      "author and source are credited.\n",
      "Data Availabilit y Statement: The data are to be\n",
      "found on the DHS website: the data are held in a\n",
      "public repository: https://dh sprogram.com /data/\n",
      "available-data sets.cfm.' metadata={'source': './example_data/journal.pone.0264429.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "# Type of docs elements\n",
    "print(f\"Type of docs elements: \\n{type(docs[0])}\")\n",
    "# Display first element of docs\n",
    "print(f\"\\nFirst element of loaded data docs: \\n{docs[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So what just happened?**\n",
    "\n",
    "- The loader reads the PDF at the specified path into memory.\n",
    "- It then extracts text data using the pypdf package.\n",
    "- Finally, it creates a LangChain Document for each page of the PDF with the page's content and some metadata about where in the document the text came from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Splitting\n",
    "We split the document into smaller (more focused) chunks that can more easily fit into an LLM's context window. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Splitting\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "documents = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chuncks: 60\n",
      "\n",
      "Type of chuncks: <class 'langchain_core.documents.base.Document'>\n",
      "\n",
      "Content of first text chunck:\n",
      "RESEA RCH ARTICL E\n",
      "Prediction of HIV status based on socio-\n",
      "behavioural characteristics in East and\n",
      "Southern Africa\n",
      "Erol Orel\n",
      "ID\n",
      "1\n",
      "*, Rachel Esra\n",
      "1\n",
      ", Janne Estill\n",
      "1,2\n",
      ", Amaury Thiabaud\n",
      "ID\n",
      "1\n",
      ", Ste Â´ phane Marchand-\n",
      "Maillet\n",
      "ID\n",
      "3\n",
      ", Aziza Merzouki\n",
      "1â˜¯\n",
      ", Olivia Keiser\n",
      "1â˜¯\n",
      "1 Institute of Global Health, University of Geneva, Geneva , Switzerlan d, 2 Institute of Mathematic al Statistics\n",
      "and Actuari al Science, Univers ity of Bern, Bern, Switzerlan d, 3 Department of Computer Science, Viper\n",
      "Group, University of Geneva, Geneva , Switzerlan d\n",
      "â˜¯ These authors contribu ted equally to this work.\n",
      "* Erol.Ore l@unige.ch\n",
      "Abstract\n",
      "Introduction\n",
      "High yield HIV testing strategies are critical to reach epidemic control in high prevalence and\n",
      "low-resource settings such as East and Southern Africa. In this study, we aimed to predict\n",
      "the HIV status of individuals living in Angola, Burundi, Ethiopia, Lesotho, Malawi, Mozam-\n",
      "bique, Namibia, Rwanda, Zambia and Zimbabwe with the highest precision and sensitivity\n"
     ]
    }
   ],
   "source": [
    "# Explore results of text splitting into chunks\n",
    "print(f\"Number of chuncks: {len(documents)}\\n\")\n",
    "print(f\"Type of chuncks: {type(documents[0])}\\n\")\n",
    "print(f\"Content of first text chunck:\\n{documents[0].page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Question**: Try changing the chunk sizes! \n",
    "- How does it affect the text splitting result?\n",
    "- How does it affect the generated answers below?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing\n",
    "## Embedding and Vector Storage\n",
    "Once we have split text chunks, we store them as vectors (embeddings) into a Vector Store. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Set your OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = config.OPENAI_API_KEY\n",
    "\n",
    "vectorstore = InMemoryVectorStore.from_documents(\n",
    "    documents=documents, embedding=OpenAIEmbeddings()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval\n",
    "We set up a retriever from the vector store to identify relevant document chunks based on a user's query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "#retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The retriever allows us to perform similarity search, and retrieve relevant text chunks based on query embeddings.\n",
    "\n",
    "This involves comparing query embeddings with stored text embeddings to retrieve the most relevant passages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query examples\n",
    "query = \"What is the goal of the study?\"\n",
    "#query = \"What is 95-95-95?\" #Check retrieved text chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of retrieved text chuncks: 4\n"
     ]
    }
   ],
   "source": [
    "retrieved_docs = retriever.invoke(query)\n",
    "\n",
    "print(f\"Number of retrieved text chuncks: {len(retrieved_docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What is the default number of retrieved text chunks?\n",
    "- Change the number of retrieved chunks, e.g. 1. See [Documentation](https://python.langchain.com/v0.1/docs/modules/data_connection/retrievers/vectorstore/#specifying-top-k)\n",
    "- See effect on LLM answer below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer Generation with OpenAI\n",
    "Here, we use the retrieved document chunks to answer the user query through an OpenAI language model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Set your OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = config.OPENAI_API_KEY\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation (Context Integration) Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The retrieved text provides context, enabling the model to generate accurate and contextually relevant responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Keep the \"\n",
    "    \"answer precise and concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the goal of the study?\n",
      "\n",
      "Answer: The goal of the study is to use machine learning methods to predict HIV positivity in East and Southern African countries by identifying common risk factors among populations with high HIV prevalence, ultimately improving testing strategies and targeting individuals for prevention services.\n",
      "\n",
      "Sources:\n",
      "\n",
      " page_content='the desired testing coverage. In our second scenario, we identified about 5% of the population\n",
      "at high risk of being HIV positive using a probability cut-off of 90%. This allowed us to identify\n",
      "more than 50% of all PLHIV with most of the tested population being HIV-positive; the\n",
      "remaining HIV-negative tested individuals are choice candidates for preventative services\n",
      "such as pre-exposure prophylaxis (PrEP). We were consequently able to maximise the efficacy\n",
      "of the testing. We believe that our method would, therefore, be a valuable addition to current\n",
      "targeted strategies.\n",
      "To our knowledge, this study is the first to use machine learning methods to predict HIV in\n",
      "generalised HIV epidemic East and Southern African countries using routinely collected sur-\n",
      "vey data. The main scope was to determine common risk factors of HIV positivity between\n",
      "countries with high HIV prevalence and the predictive ability of machine learning models' metadata={'source': './example_data/journal.pone.0264429.pdf', 'page': 10}\n",
      "\n",
      "\n",
      " page_content='Conclusions\n",
      "We trained a gradient boosting trees algorithm to find 95% of PLHIV with a precision twice\n",
      "higher than with general population testing by using only a limited number of socio-beha-\n",
      "vioural characteristics. We also successfully identified people at high risk of infection who\n",
      "may be offered pre-exposure prophylaxis or voluntary medical male circumcision. These\n",
      "findings can inform the implementation of new high-yield HIV tests and help develop very\n",
      "precise strategies based on low-resource settings constraints.\n",
      "Introduction\n",
      "In order to reach epidemic control by 2030, the Joint United Nations Programme\n",
      "(UNAIDS) has set fast track targets to rapidly scale up effective HIV services [1]. One of the\n",
      "aims is to ensure that 95% of the approximately 38 million people globally living with HIV\n",
      "(PLHIV) are aware of their HIV status and that 95% of those with HIV positive diagnoses\n",
      "are on treatment [2].' metadata={'source': './example_data/journal.pone.0264429.pdf', 'page': 1}\n",
      "\n",
      "\n",
      " page_content='vey data. The main scope was to determine common risk factors of HIV positivity between\n",
      "countries with high HIV prevalence and the predictive ability of machine learning models\n",
      "based on these common risk factors. Hence, one of the limitations of this study was the gener-\n",
      "alizability of our predictive models for countries that were not used to train the algorithm. The\n",
      "accuracy of the prediction decreased, probably due to different risk factor distributions\n",
      "between countries. Future studies could improve the generalizability by selecting more similar\n",
      "countries than the country we aimed at generalizing to or apply our algorithm to country-spe-\n",
      "cific individuals. We were also limited by the available variables in our dataset, and as a result\n",
      "we were unable to consider differences in viral load suppression, health-care expenditure, spe-\n",
      "cific HIV-related interventions, and conflicts and wars. Additionally, missing values were to' metadata={'source': './example_data/journal.pone.0264429.pdf', 'page': 10}\n",
      "\n",
      "\n",
      " page_content='F4), we further analysed the results at country level, comparing the F1, sensitivity and PPV\n",
      "between countries and the differences between observed and predicted prevalences.\n",
      "Scenarios\n",
      "We tested two scenarios: for the first scenario, the sensitivity was set to 95%, equivalent to 95%\n",
      "of PLHIV knowing their status, and we reported the corresponding precision and number of\n",
      "individuals to be tested. For the second scenario, we identified a population for which the\n",
      "probability of being HIV positive was higher than 90%. We considered that these groups of\n",
      "individuals are targets for specific testing strategies or ideal candidates for prevention services.\n",
      "Ethical review\n",
      "No ethical approval was needed for this study.\n",
      "Data and code availability\n",
      "The data supporting the findings of this study are available from the DHS Program https://\n",
      "dhsprogram.com/. The DHS Program is authorized to distribute, at no cost, unrestricted sur-' metadata={'source': './example_data/journal.pone.0264429.pdf', 'page': 4}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a chain for passing a list of Documents to a model.\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "# Create retrieval chain that retrieves documents and then passes them on.\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "results = rag_chain.invoke({\"input\": query})\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(f\"Answer: {results['answer']}\\n\")\n",
    "print(\"Sources:\")\n",
    "for document in results[\"context\"]:\n",
    "    print(f\"\\n {document}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Change the number of retrieved text chunks used as context and play with the augmented prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“ Summary\n",
    "In this notebook, you built a PDF ingestion and question-answering system using Retrieval-Augmented Generation (RAG).\n",
    "\n",
    "You covered the following aspects:\n",
    "> - Loading and processing a PDF file into manageable text chunks\n",
    "> - Vectorizing and storing the document chunks in a vector store for similarity search\n",
    "> - Setting up a retriever to find relevant sections based on a userâ€™s query\n",
    "> - Integrating with OpenAI to generate contextually relevant responses based on the retrieved information\n",
    "\n",
    "\n",
    "\n",
    "# ðŸ”— References:\n",
    "- [LangChain - PDF Q/A](https://python.langchain.com/docs/tutorials/pdf_qa/)\n",
    "- [LangChain Tutorials](https://python.langchain.com/docs/tutorials/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
